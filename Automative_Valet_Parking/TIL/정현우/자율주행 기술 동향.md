# 자율주행 기술 동향 w/ AI
- 작성일자: 2024-02-27
- 자율주행 기술 동향 및 발전 방향: AI를 중심으로.<sup>[1](#footnote_1)</sup>를 참고하여 정리함.
## history
|Ver|Describe|Author|Date|Notes|
|:---:|:---|:---:|:---:|:---|
|0.1|초안 작성|정현우|2024-02-27||
|0.1.1|라이다 센서 기반 인지 AI 기술 작성|정현우|2024-02-27||
|0.1.2|카메라 센서 기반 인지 AI 기술 작성|정현우|2024-02-28||
|0.1.2|예측 AI 기술|정현우|2024-03-04||
## 1. 인지 알고리즘
: 자율주행차량 주변의 정적, 동적 객체를 검출하여 주행 경로 상의 장애물을 인식하는 역할
1. 라이다 센서
    - 100 m 내외의 먼 위치까지의 거리를 cm 오차 내에서 정밀하게 측정
    - 360도 회전하며 거리를 측정한 3D Point Cloud 데이터를 취득할 수 있음 $\rightarrow$ but 점의 분포가 매우 희소하고 순서가 없는 비정형 데이터 $\rightarrow$ CNN을 사용하기에 부적절함.
    
    이를 해결하기 위한 방법들은 다음과 같음.
    1. Voxel 기반
        - VoxelNet<sup>[2](#footnote_2)</sup>
        - 비정형의 점군 데이터를 Voxel이라 불리는 3차원 격자로 나누어 Voxel 내 점군을 할당함.
        - 3D or 2D Convolution 연산을 통해 조감도(Bird's Eye View, BEV) 좌표계에서 객체를 검출
    2. Sparse 2D Conv 기반 (3D Conv 대안)
        - Second<sup>[3](#footnote_3)</sup>
        - Sparse Point 데이터를 효율적으로 다루기 위해 3D Convolution 대신 Sparse 2D Convolution
    3. Pillar 기반
        - PointPillars<sup>[4](#footnote_4)</sup>
        - Sparse Point 데이터를 효율적으로 다루기 위해 Voxel 대신 Pillar 형태의 격자를 이용하기도 함.
    4. Point 기반
        - PointNet<sup>[5](#footnote_5)</sup>
        - 복셀화 과정에서 데이터가 이산화되고 점군 사이의 기하학적인 데이터가 손실되는 단점을 개선하기 위해 제안
        - 점군 데이터의 순열 변화에 불변한 특성을 가지기 때문에 점군 데이터를 직접 입력받을 수 있다.
        - 입력 포인트에서 최단점 샘플링을 통해 포인트를 샘플링 $\rightarrow$ 일정 거리만큼 떨어진 주변 포인트들을 그룹화 $\rightarrow$ MLP(Multi-Layer Perceptron)를 이용하여 Feature를 추출 $\rightarrow$ 객체 검출
        - Feature 사이의 거리를 이용해 효율적으로 샘플링 하는 방법도 제안됨.
    3. Voxel + Point 기반
        - Pv-rcnn<sup>[6](#footnote_6)</sup>
2. 카메라 센서
    - depth map 기반
        1. 거리 정보 예측
            - DORN<sup>[7](#footnote_7)</sup>
            - RGB  $\rightarrow$ 추정 네트워크 $\rightarrow$ Depth Map $\rightarrow$ 3차원 정보 추출
        2. 가상 라이다
            - Pseudo-LiDAR<sup>[8](#footnote_8)</sup>
            - Depth Map의 거리 정보(w/ 카메라 내부 행렬) $\rightarrow$ 3차원 공간으로 역투영 $\rightarrow$ 점군 데이터(w/ 라이다 센서 기반 객체 검출 알고리즘) $\rightarrow$ 객체 검출
        3. 가상 라이다
            - PatchNet<sup>[9](#footnote_9)</sup>
            - RGB (w/ 2D Conv) $\rightarrow$ 객체 검출
        
        $\rightarrow$ 거리 추정 + 객체 검출 구조이기 때문에 동작 속도가 느려 성능에 제한이 됨.

    - 거리 추정 & 객체 검출 동시 학습
        1. 2D 객체 검출 네트워크 + 거리 예측 서브 네트워크
            - FCOS3D<sup>[10](#footnote_10)</sup>
            - DD3D<sup>[11](#footnote_11)</sup>

3. 센서 융합
    - 각 센서는 다음과 같은 단점이 존재함.
        - 라이다 센서: 포인트의 밀도가 거리의 제곱에 반비례하여 감소하므로 검출하려는 객체의 거리가 멀어질수록 포인트가 희소해지고 객체의 종류를 구별할 수 있는 능력이 부족해진다.
        - 카메라 센서: 광원이 부족하거나 (야간) 시계가 한정적인 상황(눈, 비, 안개 등)에서는 강인하게 동작하기 어려우며, 이미지는 거리 정보를 제공하지 않기 때문에 주변 객체의 거리 측정 성능이 한정적
    - 초기 연구
        - 이미지를 이용하여 라이다 데이터의 관심 영역을 한정시키는 연구가 진행됨.
        - 라이다 기반 객체 검출 방법이 효율적으로 개선된 이후부터는 부족한 객체 구분 능력을 이미지를 이용해 개선하려는 시도로 발전됨.
        - PointPainting<sup>[12](#footnote_12)</sup>: 입력
        - MVP<sup>[13](#footnote_13)</sup>

## 2. 예측 알고리즘
1. 단일 차량 예측
    - CNN 기반 예측
    - 인공지능 기술 개발 가속화 + 수행 데이터 다수 공개 $\rightarrow$ 다차량 예측 기술로 발전
2. 다차량 상호작용 예측
    - CNN, GNN $\rightarrow$ 차량 사이의 공간적 특성 추출
    - RNN rPduf $\rightarrow$ 과거 경로 인코딩
    - 
3. HD 지도 융합 예측

## 3. 판단 알고리즘

## 4. 계획 알고리즘

## reference
1. <a name="footnote_1">[김산민, 김영석, 전형석, 금동석, 이기범. "자율주행 기술 동향 및 발전 방향: AI를 중심으로." 한국자동차공학회논문집, vol.30, no.10, 2022, pp. 819-830.](http://journal.ksae.org/xml/34226/34226.pdf)</a>
2. <a name="footnote_2">[Zhou, Yin, and Oncel Tuzel. "Voxelnet: End-to-end learning for point cloud based 3d object detection." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.pdf)</a>
3. <a name="footnote_3">[Yan, Yan, Yuxing Mao, and Bo Li. "Second: Sparsely embedded convolutional detection." Sensors 18.10 (2018): 3337.](https://www.mdpi.com/1424-8220/18/10/3337/pdf)</a>
4. <a name="footnote_4">[Lang, Alex H., et al. "Pointpillars: Fast encoders for object detection from point clouds." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.](https://openaccess.thecvf.com/content_CVPR_2019/papers/Lang_PointPillars_Fast_Encoders_for_Object_Detection_From_Point_Clouds_CVPR_2019_paper.pdf)</a>
5. <a name="footnote_5">[Lang, Alex H., et al. "Qi, Charles R., et al. "Pointnet: Deep learning on point sets for 3d classification and segmentation." Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.](https://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf)</a>
6. <a name="footnote_6">[Shi, Shaoshuai, et al. "Pv-rcnn: Point-voxel feature set abstraction for 3d object detection." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.](https://openaccess.thecvf.com/content_CVPR_2020/papers/Shi_PV-RCNN_Point-Voxel_Feature_Set_Abstraction_for_3D_Object_Detection_CVPR_2020_paper.pdf)</a>
7. <a name="footnote_7">[Fu, Huan, et al. "Deep ordinal regression network for monocular depth estimation." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.](https://openaccess.thecvf.com/content_cvpr_2018/papers/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.pdf)</a>
8. <a name="footnote_8">[Wang, Yan, et al. "Pseudo-lidar from visual depth estimation: Bridging the gap in 3d object detection for autonomous driving." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Pseudo-LiDAR_From_Visual_Depth_Estimation_Bridging_the_Gap_in_3D_CVPR_2019_paper.pdf)</a>
9. <a name="footnote_9">[Ma, Xinzhu, et al. "Rethinking pseudo-lidar representation." Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16. Springer International Publishing, 2020.](https://arxiv.org/pdf/2008.04582.pdf)</a>
10. <a name="footnote_10">[Wang, Tai, et al. "Fcos3d: Fully convolutional one-stage monocular 3d object detection." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.](https://openaccess.thecvf.com/content/ICCV2021W/3DODI/papers/Wang_FCOS3D_Fully_Convolutional_One-Stage_Monocular_3D_Object_Detection_ICCVW_2021_paper.pdf)</a>
11. <a name="footnote_11">[Park, Dennis, et al. "Is pseudo-lidar needed for monocular 3d object detection?." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.](https://openaccess.thecvf.com/content/ICCV2021/papers/Park_Is_Pseudo-Lidar_Needed_for_Monocular_3D_Object_Detection_ICCV_2021_paper.pdf)</a>
12. <a name="footnote_12">[Vora, Sourabh, et al. "Pointpainting: Sequential fusion for 3d object detection." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.](https://openaccess.thecvf.com/content_CVPR_2020/papers/Vora_PointPainting_Sequential_Fusion_for_3D_Object_Detection_CVPR_2020_paper.pdf)</a>
13. <a name="footnote_13">[Yin, Tianwei, Xingyi Zhou, and Philipp Krähenbühl. "Multimodal virtual point 3d detection." Advances in Neural Information Processing Systems 34 (2021): 16494-16507.](https://proceedings.neurips.cc/paper_files/paper/2021/file/895daa408f494ad58006c47a30f51c1f-Paper.pdf)</a>
14. [박예성, "3D 인공지능 데이텨 Point Cloud(1): Point Cloud 데이터와 이를 다루는 3D 인공지능의 발전", Testworks, 2021.09.07., https://blog.testworks.co.kr/3d-ai-data-point-cloud/](https://blog.testworks.co.kr/3d-ai-data-point-cloud/)